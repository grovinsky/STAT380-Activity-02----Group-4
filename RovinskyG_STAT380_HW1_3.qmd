---
title: "STAT 380 HW #1.3 - SLR/MLR"
author: "Grace Rovinsky"
format: html
date: now
---

## Due: Sunday, February, 22nd by 11:59 PM

## Instructions

In class, we covered the basics of data wrangling with the basics of linear regression models. The activities that follow are meant to provide further practice with these concepts. You should insert code chunks and/or text to answer each of the questions below. Text-based answers should be complete sentences.

At the conclusion to the activity, you should upload

1. your .html file named LastnameFirstInitial_STAT380_HW1_3.html 
2. your .Rmd file named LastnameFirstInitial_STAT380_HW1_3.qmd

to Question 1 of the HW #1.3 Assignment in MyOpenMath.

```{r}
#| label: setup1
#| include: FALSE
#| echo: FALSE
knitr::opts_chunk$set(echo = TRUE)

```

## Setup - Load Libraries and Data
```{r}
#| label: setup2
#| warning: FALSE

#Add libraries as needed
library(tidyverse)
library(kableExtra)



#Read in Dataset - This needs to be a relative file path so it works on any computer
nova_data <- read.csv("~/Downloads/NOVA.csv")
```

## Problem 1. Housing Prices in Northern Virginia - Data Cleaning

The file NOVA.csv contains a sample of properties in the Northern Virginia region (Arlington County, Fairfax County, and so on) listed on Remax.com in April 2019. The data set contains the following variables:

* Bedrooms - number of bedrooms
* Bathrooms - number of bathrooms
* LivingSQFT - square footage of living area
* Age - age of the house in years
* DistToWH - distance from house to the White House in miles
* LotSize - lot size in acres
* ListingType - type of property (Condo/Townhome OR Single Family)
* Floors - the number of floors in the house
* CountySchool - the school district for the country 
* Garage - the number of garage stalls
* Price - the price of the home in dollars
     

#### a. Our ultimate goal here is to model home price in Northern Virginia using various features of the homes that we have access to. Before we do so, we need to investigate our data and perform some data wrangling procedures to prepare for modeling. To ensure that you are always referencing the full dataset when implementing your data wrangling without overwriting the original data, you should store a copy of the dataframe named `NOVA2`. Then, use `NOVA2` in the remaining parts of Problem 1.
```{r}
NOVA2 <- data.frame(nova_data)
```
#### b. We can think of CountySchool as a proxy for the propertyâ€™s county. How many properties are included from each county? Display these values in a properly formatted frequency table.
```{r}
countyTable <- NOVA2 %>%
      group_by(CountySchool) %>%
      summarise(
      Properties = n()
)
countyTable %>%
    kable(caption = "Number of Properties in each County in Northern Virginia")
```

#### c. Use the code below to generate a histogram of `Price` using a binwidth of 200000.  The distribution of house prices is right skewed with several outliers. The heavy red line represents a price of three million dollars ($3M). Properties with a price over $3M are emphasized by the red circles.
- NOTE 1: Putting a comma in the number 200,000 when setting the binwidth in R will cause a problem. 
## **NOTE 2: For this part, all you have to do is remove the `eval = FALSE` in the R chunk header and make sure that the plot displays in your markdown document.**

```{r}
#| label: hist_prices
#| echo: false

#Create histogram of Prices and highlight outliers
ggplot(
  data = NOVA2, 
  mapping = aes(x = Price)
  ) +
  geom_histogram(
    binwidth = 200000, 
    color = "black", 
    fill = "lightblue"
    ) +
  labs( #Label Axes with words not variable names
    x = "Price (in Dollars)",
    y = "Number of Properties"
    ) +
  scale_x_continuous(
    labels = scales::comma #Removes scientific notation from axis labels
    ) + 
  geom_vline( #Adds vertical line at $3M
    xintercept = 3000000, 
    color = "red", 
    linewidth = 2
    ) +
  geom_point( #Adds circles (large hollow points) only for houses with a price over $3M
    data = NOVA2[NOVA2$Price > 3000000,],
    aes(x = Price, y = 0), 
    color = "red", 
    shape = 1, 
    size = 10)
``` 

#### d. To investigate what makes these expensive properties unusual, create and display a properly formatted table (not raw output) showing the properties with a price of more than $3M. (Do NOT overwrite NOVA2 with a filtered version of the dataset when doing this step.) What do you notice about these properties?
```{r}
#| label: over3M_properties
#| echo: false
over3MTable <- NOVA2 %>%
  filter(Price > 3000000)
kable(over3MTable,
      caption = "Properties with Price Greater Than $3M")

```



#### e. Choose another variable to investigate from our dataset. Create an appropriate data visualization for exploring the variable. Are there any unusual values (potential outliers) that you notice? Provide a justification as to why we should/should not remove any observations based on this variable.
```{r}
#| label: distToWHPlot
#| echo: false
ggplot(NOVA2, aes(x= DistToWH, y = LotSize)) +
  geom_point() +
  labs(
    title = "Northern Virginia Houses by Lot Size and Distance from White House",
    x = "Lot Size (acres)",
    y = "Distance from White House (miles)"
  )
```
I chose to investigate the LotSize and DistToWH variables using a scatterplot. There are two possible outliers, which are the houses that have a lot size of 7 and 8 acres. All other houses have lot sizes of 6 acres or less. There are not many outliers for DistToWH. All houses fall somewhere between 2500 to 45000 miles from the White House. 


#### f. We are going to refine the scope of our analysis. We only want to model properties worth less the $3M from Arlington and Fairfax counties. Since Loudoun and Prince William counties have very few observations and we have not collected enough data from very expensive properties (only 5 properties over $3M), we do not really have enough data to accurately model these properties. Write code that removes the outliers (prices over $3M) AND any properties from Loudoun and Prince William counties from `NOVA2`. How many rows remain in `NOVA2`? 
```{r}
#| label: refineScope
#| echo: false
NOVA2 <- NOVA2 %>%
  filter(
    Price < 3000000,
    CountySchool != "LOUDOUN COUNTY PUBLIC SCHOOLS",
    CountySchool != "PRINCE WILLIAM COUNTY PUBLIC SCHOOLS"
  )

nrow(NOVA2)
```
1039 rows remain in NOVA2 after removing houses with prices over $3M and properties from Loudoun and Prince William counties.


#### g. In modeling housing prices, it is common to do a log (natural) transformation of the `Price`. Create a new variable called `logPrice` in `NOVA2` that represents the natural log of the house's price. Then, create a histogram of `logPrice` using `ggplot`, modify the binwidth so that you are not using the default plot, and comment on the shape of the distribution.
```{r}
#| label: logprice
#| echo: false
NOVA2 <- NOVA2 %>%
  mutate(logPrice = log(Price))

ggplot(NOVA2, aes(x = logPrice)) +
  geom_histogram(binwidth = 0.1, color = "white") +
  labs(title = "Histogram of Log-Transformed Housing Prices",
       x = "Log of Price",
       y = "Count")

```
The shape of the distribution is mostly normal and symmetric but slightly right-skewed.


#### h. Create dummy (indicator) variables for `ListingType` and `CountySchool`. In particular, create a variable in `NOVA2` called `Single` that takes a value of 1 if the property is a "Single Family" home and a value of 0 otherwise. Similarly, create a variable called `Arlington` that takes a value of 1 when the county school is "ARLINGTON COUNTY PUBLIC SCHOOLS" and 0 otherwise.

NOTE: To verify that you have performed these steps correctly, double check that the mean of log price is 13.50511 and the mean of Arlington is 0.2637151 (which is the proportion of properties in NOVA2 from Arlington). If you are NOT getting those EXACT (not close) answers, it will affect future answers. You should fix this before moving forward.

```{r}
#| label: indicatorVariables
#| echo: false
NOVA2 <- NOVA2 %>%
  mutate(
    Single = ifelse(ListingType == "Single Family", 1, 0),
    Arlington = ifelse(CountySchool == "ARLINGTON COUNTY PUBLIC SCHOOLS", 1, 0)
  )

mean(NOVA2$logPrice)
mean(NOVA2$Arlington)

```

## Problem 2. Housing Prices in Northern Virginia - Simple Linear Regression

#### a. Suppose we want to build a simple linear regression model for predicting `logPrice` as a function of `Bathrooms` using the `NOVA2` dataset created through the various steps in Problem 1. We should first determine if a linear relationship is appropriate. Create a scatterplot showing the relationship between the variables and include a smooth trendline (Hint: Use geom_smooth). Do you think a linear relationship is appropriate? Why or why not?
```{r}
#| label: linearrel
#| echo: false
ggplot(NOVA2, aes(x= Bathrooms, y = logPrice)) +
  geom_point() +
  geom_smooth() +
  labs(
    title = "Log of Price and Number of Bathrooms",
    x = "Number of Bathrooms",
    y = "LogPrice"
  )
```
Using geom_smooth, we can see that the line is somewhat linear. A linear relationship would be appropriate for this model.


#### b. Regardless of your answer to Part a., build the regression model, display a summary of the model, and write the estimated regression equation. 
* HINT: I have provided code that you can modify for entering the equation.

$$\hat{y}_i = b_{0} + b_{baths}x_{i,baths}$$
```{r}
#| label: regressionmodel
#| echo: false
regressionModel <- lm(logPrice ~ Bathrooms, data = NOVA2)

summary(regressionModel)

```
The estimated regression equation is logPrice = 12.567869 + 0.249756(Bathrooms).

#### c. Write an interpretation of the bathroom coefficient (i.e. How does number of bathrooms affect the log(Price)?) 

For each bathroom in a house, the log(Price) increases by about 24.9756%.

#### d. Report and interpret $R^2$ for this model.
The R-squared is 0.4769. This means that about 47.69% of the variability in log(Price) is explained by the number of bathrooms in this model.

#### e. What is the average amount by which the `logPrice` will deviate from the prediction made by the regression line?
The average amount that the logPrice will deviate from the prediction is 0.364, which is the residual standard error in the regression model summary.

#### f. Construct a QQ-Plot for the SLR model. Does this plot suggest that we meet the normality assumption of SLR?
```{r}
#| label: qqplot
#| echo: false

ggplot(data.frame(residuals = resid(regressionModel)),
       aes(sample = residuals)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "QQ-Plot for Regression Model",
       x = "Theoretical Quantiles",
       y = "Residuals")

```
This plot suggests that we meet the normality suggestion for simple linear regression. The points only deviate from the line at the tails, but are mostly very close to the line.


#### g. Construct a plot to assess the assumptions of constant variance and a mean of 0 for our residuals. Comment on the appropriateness of those assumptions for this model.
```{r}
#| label: plot2
#| echo: false
ggplot(NOVA2, aes(x= fitted(regressionModel), y = resid(regressionModel))) +
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(title = "Residuals vs. Predicted Values",
       x = "Predicted Values",
       y = "Residuals")


```
The mean of the residuals should be close to 0, since the points are evenly distributed above and below the line at 0. We may not be able to assume constant variance since the spread of the points above and below the line at y = 0 slightly decreases as predicted values increase.

## Problem 3 - Housing Prices in Northern Virginia - Multiple Linear Regression


#### a. Using `NOVA2`, build a regression model for `logPrice` using `Bathrooms` and the `Arlington` indicator. Display a summary of the model, and write the estimated regression equation.

* HINT: I have provided code that you can modify for entering the equation.

$$\hat{y}_i = b_{0} + b_{baths}x_{i,baths} + b_{Arlington}x_{i,Arlington}$$
```{r}
#| label: plot3
#| echo: false
regressionModel2 <- lm(logPrice ~ Bathrooms + Arlington, data = NOVA2)

summary(regressionModel2)
```
The estimated regression equation is logPrice = 12.483495 + 0.238603(Bathrooms) + 0.478650(Arlington).

#### b. Using the estimated regression equation from Part a., predict the `logPrice` of a house with 2 bathrooms in Fairfax County. NOTE: I want you to show your work and do this calculation manually rather than writing R code to predict this value. (I am trying to give you practice for something I could ask on a pencil/paper exam.) You can check your work with R if you'd like.

logPrice = 12.483495 + 0.238603(2) + 0.478650(0)
logPrice = 12.960701


#### c. Explain the relationship between the number of bathrooms and `logPrice` after accounting for location (`Arlington`).
After accounting for being in Arlington, each bathroom in a house increases logPrice by about 23.8%.



#### d. Interpret the coefficient (or slope) of the `Arlington` indicator in the context of the problem.
If a house is in Arlington, the logPrice increases by 47.865% as compared to not being in Arlington.


#### f. What proportion of the total variation in `logPrice` is explained by the model using `Bathrooms` and `Arlington`?
The proportion of the total variation in logPrice explained by the model using Bathrooms and Arlington is 0.6519, which is the R-squared value.


#### g. Interpret the residual standard error in the context of this model.
The residual standard error for this model is 0.297. This means that the predicted logPrice varies from the actual log of each price by about 0.297.


#### h. What proportion of the remaining variance in `logPrice` is explained by the model using `Bathrooms` and `Arlington` that cannot be explained by `Bathrooms` alone?

```{r}
baths <- summary(regressionModel)$r.squared
baths_arlington <- summary(regressionModel2)$r.squared
var <- (baths_arlington-baths)/(1-baths)
var
```

The proportion of the remaining variance in logPrice is explained by the model using Bathrooms and Arlington that cannot be explained by Bathrooms alone is 0.3346342.
